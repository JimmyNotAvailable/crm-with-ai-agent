"""
RAG Service - Main service for RAG-based Q&A
T√≠ch h·ª£p retriever v√† Gemini LLM ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi t·ª± nhi√™n
"""
from typing import Dict, Any, Optional, List
import os
import re
from pathlib import Path

from ai_modules.core.config import ai_config
from .retriever import PolicyRetriever, ProductRetriever, DEFAULT_CHROMA_PATH


class RAGService:
    """
    RAG Service cho Customer Service Agent
    
    Ch·ª©c nƒÉng:
    - Retrieve th√¥ng tin t·ª´ Policy/FAQ (ChromaDB)
    - Retrieve th√¥ng tin s·∫£n ph·∫©m (ChromaDB)
    - Generate c√¢u tr·∫£ l·ªùi t·ª± nhi√™n v·ªõi Gemini LLM
    
    LLM Priority: Gemini > OpenAI > Mock
    """
    
    def __init__(self, chroma_path: Optional[str] = None):
        # Use default chroma path from retriever module if not specified
        self.chroma_path = chroma_path or DEFAULT_CHROMA_PATH
        
        # Demo mode MUST be explicitly enabled via env var
        self.demo_mode = os.getenv("DEMO_MODE", "false").lower() == "true"
        
        # Initialize retrievers
        self.policy_retriever = PolicyRetriever(self.chroma_path)
        self.product_retriever = ProductRetriever(self.chroma_path)
        
        # Initialize LLM client (Gemini first)
        self._init_llm_client()
    
    def _init_llm_client(self):
        """
        Initialize LLM client
        Priority: Gemini > OpenAI > None (falls back to error message)
        """
        self.llm_client = None
        self.llm_provider = None
        
        if self.demo_mode:
            print("[RAGService] Running in DEMO_MODE - LLM disabled")
            return
        
        # Try Gemini first (Primary)
        gemini_key = os.getenv("GEMINI_API_KEY") or ai_config.gemini_api_key
        if gemini_key:
            try:
                from google import genai
                self.llm_client = genai.Client(api_key=gemini_key)
                self.llm_provider = "gemini"
                print("[RAGService] Using Gemini LLM")
                return
            except ImportError:
                print("[RAGService] google-genai not installed, trying OpenAI...")
            except Exception as e:
                print(f"[RAGService] Gemini init error: {e}")
        
        # Fallback to OpenAI
        openai_key = os.getenv("OPENAI_API_KEY") or ai_config.openai_api_key
        if openai_key:
            try:
                from openai import OpenAI
                self.llm_client = OpenAI(api_key=openai_key)
                self.llm_provider = "openai"
                print("[RAGService] Using OpenAI LLM")
                return
            except ImportError:
                print("[RAGService] openai not installed")
            except Exception as e:
                print(f"[RAGService] OpenAI init error: {e}")
        
        print("[RAGService] WARNING: No LLM configured! Set GEMINI_API_KEY or OPENAI_API_KEY")
    
    def query(
        self,
        question: str,
        category: Optional[str] = None,
        top_k_policy: int = 4,
        top_k_product: int = 6
    ) -> Dict[str, Any]:
        """
        Query RAG pipeline
        
        Args:
            question: C√¢u h·ªèi c·ªßa kh√°ch h√†ng
            category: Filter theo category s·∫£n ph·∫©m (optional)
            top_k_policy: S·ªë l∆∞·ª£ng policy docs ƒë·ªÉ retrieve
            top_k_product: S·ªë l∆∞·ª£ng product docs ƒë·ªÉ retrieve
            
        Returns:
            Dict v·ªõi answer v√† sources
        """
        # Retrieve relevant documents
        policy_docs = self.policy_retriever.retrieve(
            query=question,
            top_k=top_k_policy
        )
        
        product_docs = self.product_retriever.retrieve(
            query=question,
            category=category,
            top_k=top_k_product
        )
        
        if not policy_docs and not product_docs:
            return {
                "answer": "Hi·ªán t·∫°i h·ªá th·ªëng ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p ƒë·ªÉ t∆∞ v·∫•n cho y√™u c·∫ßu n√†y.",
                "sources": [],
                "confidence": 0.0
            }
        
        # Build context
        context = self._build_context(policy_docs, product_docs)
        
        # Generate answer with LLM (natural language)
        if self.demo_mode:
            answer = self._generate_demo_answer(question, policy_docs, product_docs)
        elif self.llm_client:
            answer = self._generate_llm_answer(question, context)
        else:
            # No LLM configured - return structured data with friendly message
            answer = self._generate_fallback_answer(question, policy_docs, product_docs)
        
        # Build sources
        sources = self._build_sources(policy_docs, product_docs)
        
        return {
            "answer": answer,
            "sources": sources,
            "confidence": self._calculate_confidence(policy_docs, product_docs)
        }
    
    def compare_products(
        self,
        query: str,
        product_names: List[str],
        category: Optional[str] = None,
        top_k: int = 6
    ) -> Dict[str, Any]:
        """
        So s√°nh nhi·ªÅu s·∫£n ph·∫©m d·ª±a tr√™n query v√† t√™n s·∫£n ph·∫©m.
        
        Args:
            query: C√¢u h·ªèi so s√°nh c·ªßa kh√°ch h√†ng
            product_names: Danh s√°ch t√™n s·∫£n ph·∫©m c·∫ßn so s√°nh
            category: Filter theo category (optional)
            top_k: S·ªë s·∫£n ph·∫©m t·ªëi ƒëa ƒë·ªÉ retrieve m·ªói query
            
        Returns:
            Dict v·ªõi comparison, products, comparison_table
        """
        all_products = []
        
        # Retrieve products cho m·ªói t√™n s·∫£n ph·∫©m
        for name in product_names:
            docs = self.product_retriever.retrieve(
                query=name,
                category=category,
                top_k=top_k // len(product_names) + 1 if product_names else top_k
            )
            for doc in docs:
                product_info = self._parse_product_from_doc(doc)
                if product_info and product_info not in all_products:
                    all_products.append(product_info)
        
        # N·∫øu ch∆∞a ƒë·ªß s·∫£n ph·∫©m, th·ª≠ query chung
        if len(all_products) < 2:
            docs = self.product_retriever.retrieve(
                query=query,
                category=category,
                top_k=top_k
            )
            for doc in docs:
                product_info = self._parse_product_from_doc(doc)
                if product_info and product_info not in all_products:
                    all_products.append(product_info)
        
        if len(all_products) < 2:
            return {
                "comparison": "Kh√¥ng t√¨m ƒë·ªß s·∫£n ph·∫©m ƒë·ªÉ so s√°nh.",
                "products": all_products,
                "comparison_table": None,
                "confidence": 0.0
            }
        
        # Limit to top products
        products_to_compare = all_products[:5]
        
        # Build comparison table
        comparison_table = self._build_comparison_table(products_to_compare)
        
        # Generate comparison text
        if self.demo_mode or not self.llm_client:
            comparison = self._generate_mock_comparison(products_to_compare, comparison_table)
        else:
            comparison = self._generate_llm_comparison(query, products_to_compare)
        
        return {
            "comparison": comparison,
            "products": products_to_compare,
            "comparison_table": comparison_table,
            "confidence": 0.85
        }
    
    def _parse_product_from_doc(self, doc: Dict) -> Optional[Dict]:
        """Parse product info from retrieved document"""
        content = doc.get("content", "")
        metadata = doc.get("metadata", {})
        
        # Try to extract structured info from content
        product = {
            "id": metadata.get("product_id") or metadata.get("id"),
            "name": metadata.get("name", ""),
            "price": metadata.get("price", 0),
            "category": metadata.get("category", ""),
            "specs": {},
            "description": "",
            "distance": doc.get("distance", 0)
        }
        
        # Parse content for more details
        lines = content.split("\n")
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Extract name if not in metadata
            if not product["name"] and ("t√™n" in line.lower() or line.startswith("**")):
                # Clean markdown
                name = re.sub(r'\*+', '', line).strip()
                name = re.sub(r'^(t√™n|s·∫£n ph·∫©m)[:\s]*', '', name, flags=re.IGNORECASE).strip()
                if name:
                    product["name"] = name
            
            # Extract price
            if "gi√°" in line.lower() or "price" in line.lower():
                price_match = re.search(r'[\d,.]+', line.replace('.', '').replace(',', ''))
                if price_match:
                    try:
                        product["price"] = float(price_match.group())
                    except ValueError:
                        pass
            
            # Extract specs (key: value patterns)
            if ":" in line:
                parts = line.split(":", 1)
                if len(parts) == 2:
                    key = parts[0].strip().lower()
                    value = parts[1].strip()
                    if key and value and len(key) < 30:
                        product["specs"][key] = value
        
        # Use content as description if no structured data
        if not product["name"]:
            product["name"] = content[:50] + "..." if len(content) > 50 else content
        
        product["description"] = content[:200]
        
        return product if product.get("name") else None
    
    def _build_comparison_table(self, products: List[Dict]) -> Dict[str, List]:
        """Build comparison table from products"""
        if not products:
            return {}
        
        # Collect all spec keys
        all_specs = set()
        for p in products:
            all_specs.update(p.get("specs", {}).keys())
        
        # Common comparison attributes
        table = {
            "products": [p.get("name", "N/A") for p in products],
            "prices": [p.get("price", 0) for p in products],
            "categories": [p.get("category", "N/A") for p in products],
        }
        
        # Add specs to table
        for spec in all_specs:
            table[spec] = [p.get("specs", {}).get(spec, "N/A") for p in products]
        
        return table
    
    def _generate_llm_comparison(self, query: str, products: List[Dict]) -> str:
        """Generate comparison using LLM"""
        products_text = []
        for i, p in enumerate(products, 1):
            specs_text = "\n".join([f"  - {k}: {v}" for k, v in p.get("specs", {}).items()])
            products_text.append(f"""
S·∫¢N PH·∫®M {i}: {p.get('name', 'N/A')}
- Gi√°: {p.get('price', 0):,.0f} VNƒê
- Danh m·ª•c: {p.get('category', 'N/A')}
{specs_text}
- M√¥ t·∫£: {p.get('description', '')[:100]}
""")
        
        prompt = f"""
B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n mua h√†ng. H√£y so s√°nh c√°c s·∫£n ph·∫©m sau ƒë·ªÉ gi√∫p kh√°ch h√†ng l·ª±a ch·ªçn.

C√ÇU H·ªéI KH√ÅCH H√ÄNG:
{query}

TH√îNG TIN S·∫¢N PH·∫®M:
{''.join(products_text)}

Y√äU C·∫¶U:
1. So s√°nh c√°c ƒëi·ªÉm gi·ªëng v√† kh√°c nhau ch√≠nh
2. N√™u ∆∞u/nh∆∞·ª£c ƒëi·ªÉm m·ªói s·∫£n ph·∫©m
3. ƒê∆∞a ra g·ª£i √Ω ph√π h·ª£p v·ªõi nhu c·∫ßu trong c√¢u h·ªèi
4. Tr√¨nh b√†y d·ªÖ ƒë·ªçc v·ªõi bullet points
5. Tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp

SO S√ÅNH:
"""
        
        try:
            if self.llm_provider == "gemini":
                response = self.llm_client.models.generate_content(
                    model=ai_config.gemini_model,
                    contents=prompt
                )
                return (response.text or "").strip()
            
            elif self.llm_provider == "openai":
                response = self.llm_client.chat.completions.create(
                    model=ai_config.openai_model,
                    messages=[
                        {"role": "system", "content": "B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n mua h√†ng chuy√™n nghi·ªáp."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=800,
                    temperature=0.7
                )
                return response.choices[0].message.content.strip()
            
        except Exception as e:
            return self._generate_mock_comparison(products, None)
        
        return self._generate_mock_comparison(products, None)
    
    def _generate_mock_comparison(
        self, 
        products: List[Dict], 
        table: Optional[Dict]
    ) -> str:
        """Generate mock comparison for demo mode"""
        lines = ["**SO S√ÅNH S·∫¢N PH·∫®M**\n"]
        
        # Product summaries
        for i, p in enumerate(products, 1):
            lines.append(f"### {i}. {p.get('name', 'N/A')}")
            lines.append(f"**Gi√°:** {p.get('price', 0):,.0f} VNƒê")
            lines.append(f"**Danh m·ª•c:** {p.get('category', 'N/A')}")
            
            # Specs
            specs = p.get("specs", {})
            if specs:
                lines.append("**Th√¥ng s·ªë:**")
                for k, v in list(specs.items())[:5]:
                    lines.append(f"  - {k}: {v}")
            lines.append("")
        
        # Comparison summary
        if len(products) >= 2:
            lines.append("---")
            lines.append("### T√ìM T·∫ÆT SO S√ÅNH\n")
            
            # Price comparison
            prices = [(p.get("name", "")[:20], p.get("price", 0)) for p in products]
            sorted_prices = sorted(prices, key=lambda x: x[1])
            
            lines.append("**Gi√° c·∫£:**")
            lines.append(f"  - R·∫ª nh·∫•t: {sorted_prices[0][0]} ({sorted_prices[0][1]:,.0f}‚Ç´)")
            lines.append(f"  - ƒê·∫Øt nh·∫•t: {sorted_prices[-1][0]} ({sorted_prices[-1][1]:,.0f}‚Ç´)")
            lines.append("")
            
            lines.append("**G·ª£i √Ω:**")
            lines.append(f"  - N·∫øu ∆∞u ti√™n gi√°: Ch·ªçn **{sorted_prices[0][0]}**")
            lines.append(f"  - N·∫øu ∆∞u ti√™n t√≠nh nƒÉng cao c·∫•p: Xem x√©t **{sorted_prices[-1][0]}**")
        
        lines.append("\n*Nh·∫•n n√∫t b√™n d∆∞·ªõi ƒë·ªÉ ƒë·∫∑t h√†ng ho·∫∑c xem chi ti·∫øt.*")
        
        return "\n".join(lines)
    
    def _build_context(
        self, 
        policy_docs: List[Dict], 
        product_docs: List[Dict]
    ) -> str:
        """Build context string from retrieved documents"""
        context_blocks = []
        
        if product_docs:
            context_blocks.append("### TH√îNG TIN S·∫¢N PH·∫®M")
            for i, d in enumerate(product_docs, 1):
                context_blocks.append(f"[PRODUCT {i}] {d['content']}")
        
        if policy_docs:
            context_blocks.append("### CH√çNH S√ÅCH LI√äN QUAN")
            for i, d in enumerate(policy_docs, 1):
                context_blocks.append(f"[POLICY {i}] {d['content']}")
        
        return "\n\n".join(context_blocks)
    
    def _generate_llm_answer(self, question: str, context: str) -> str:
        """Generate answer using LLM"""
        prompt = f"""
B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n mua h√†ng chuy√™n nghi·ªáp.

NHI·ªÜM V·ª§:
- Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng d·ª±a HO√ÄN TO√ÄN v√†o d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p.
- KH√îNG b·ªãa th√¥ng tin, KH√îNG d√πng ki·∫øn th·ª©c ngo√†i CONTEXT.
- Tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp.

CONTEXT:
{context}

C√ÇU H·ªéI KH√ÅCH H√ÄNG:
{question}

TR·∫¢ L·ªúI:
"""
        
        try:
            if self.llm_provider == "gemini":
                response = self.llm_client.models.generate_content(
                    model=ai_config.gemini_model,
                    contents=prompt
                )
                return (response.text or "").strip()
            
            elif self.llm_provider == "openai":
                response = self.llm_client.chat.completions.create(
                    model=ai_config.openai_model,
                    messages=[
                        {"role": "system", "content": "B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n mua h√†ng chuy√™n nghi·ªáp."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=512,
                    temperature=0.7
                )
                return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"Xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë. Vui l√≤ng th·ª≠ l·∫°i sau. ({str(e)})"
        
        return "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."
    
    def _generate_mock_answer(
        self, 
        question: str, 
        policy_docs: List[Dict], 
        product_docs: List[Dict]
    ) -> str:
        """Generate mock answer for demo mode"""
        lines = ["**[DEMO MODE]**\n"]
        
        if product_docs:
            lines.append(f"T√¨m th·∫•y {len(product_docs)} s·∫£n ph·∫©m li√™n quan:")
            for doc in product_docs[:3]:
                content_preview = doc.get('content', '')[:100]
                lines.append(f"  - {content_preview}...")
            lines.append("")
        
        if policy_docs:
            lines.append(f"T√¨m th·∫•y {len(policy_docs)} ch√≠nh s√°ch li√™n quan:")
            for doc in policy_docs[:2]:
                content_preview = doc.get('content', '')[:100]
                lines.append(f"  - {content_preview}...")
        
        lines.append("\n*ƒê√¢y l√† ph·∫£n h·ªìi demo. Production s·∫Ω d√πng Gemini/OpenAI.*")
        
        return "\n".join(lines)
    
    def _generate_demo_answer(
        self, 
        question: str, 
        policy_docs: List[Dict], 
        product_docs: List[Dict]
    ) -> str:
        """Generate demo answer khi DEMO_MODE=true"""
        lines = ["üîß **[CH·∫æ ƒê·ªò DEMO]**\n"]
        
        if product_docs:
            lines.append(f"üì¶ T√¨m th·∫•y **{len(product_docs)}** s·∫£n ph·∫©m li√™n quan:")
            for i, doc in enumerate(product_docs[:3], 1):
                name = doc.get('metadata', {}).get('title', 'S·∫£n ph·∫©m')
                price = doc.get('metadata', {}).get('price', 'N/A')
                lines.append(f"  {i}. {name} - {price:,}ƒë" if isinstance(price, (int, float)) else f"  {i}. {name}")
            lines.append("")
        
        if policy_docs:
            lines.append(f"üìã T√¨m th·∫•y **{len(policy_docs)}** ch√≠nh s√°ch li√™n quan:")
            for i, doc in enumerate(policy_docs[:2], 1):
                domain = doc.get('metadata', {}).get('domain', 'Ch√≠nh s√°ch')
                lines.append(f"  {i}. {domain}")
        
        lines.append("\n---")
        lines.append("*üí° ƒê·ªÉ c√≥ c√¢u tr·∫£ l·ªùi t·ª± nhi√™n, vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY trong file .env*")
        
        return "\n".join(lines)
    
    def _generate_fallback_answer(
        self, 
        question: str, 
        policy_docs: List[Dict], 
        product_docs: List[Dict]
    ) -> str:
        """
        Generate fallback answer khi kh√¥ng c√≥ LLM
        V·∫´n cung c·∫•p th√¥ng tin h·ªØu √≠ch t·ª´ RAG
        """
        lines = []
        
        # Greeting
        lines.append("Xin ch√†o! T√¥i ƒë√£ t√¨m th·∫•y m·ªôt s·ªë th√¥ng tin c√≥ th·ªÉ gi√∫p b·∫°n:\n")
        
        # Products
        if product_docs:
            lines.append("**üõçÔ∏è S·∫£n ph·∫©m ph√π h·ª£p:**")
            for doc in product_docs[:3]:
                meta = doc.get('metadata', {})
                name = meta.get('title') or meta.get('name', 'S·∫£n ph·∫©m')
                price = meta.get('price')
                category = meta.get('category', '')
                
                if price:
                    lines.append(f"‚Ä¢ **{name}** - {price:,}ƒë ({category})" if isinstance(price, (int, float)) else f"‚Ä¢ **{name}** - {price} ({category})")
                else:
                    lines.append(f"‚Ä¢ **{name}** ({category})")
            lines.append("")
        
        # Policies
        if policy_docs:
            lines.append("**üìã Th√¥ng tin ch√≠nh s√°ch:**")
            for doc in policy_docs[:2]:
                content = doc.get('content', '')[:200]
                if content:
                    lines.append(f"‚Ä¢ {content}...")
            lines.append("")
        
        # CTA
        lines.append("---")
        lines.append("*ƒê·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt h∆°n, b·∫°n c√≥ th·ªÉ li√™n h·ªá hotline ho·∫∑c chat tr·ª±c ti·∫øp v·ªõi nh√¢n vi√™n.*")
        
        return "\n".join(lines)
    
    def _build_sources(
        self, 
        policy_docs: List[Dict], 
        product_docs: List[Dict]
    ) -> List[Dict[str, Any]]:
        """Build sources list from retrieved documents"""
        sources = []
        
        for d in product_docs + policy_docs:
            sources.append({
                "type": d.get("metadata", {}).get("type", "unknown"),
                "distance": round(d.get("distance", 0), 4),
                "meta": d.get("metadata", {})
            })
        
        return sources
    
    def _calculate_confidence(
        self, 
        policy_docs: List[Dict], 
        product_docs: List[Dict]
    ) -> float:
        """Calculate confidence score based on retrieved documents"""
        if not policy_docs and not product_docs:
            return 0.0
        
        all_docs = policy_docs + product_docs
        avg_distance = sum(d.get("distance", 1.0) for d in all_docs) / len(all_docs)
        
        # Convert distance to confidence (lower distance = higher confidence)
        confidence = max(0.0, 1.0 - avg_distance)
        return round(confidence, 2)
